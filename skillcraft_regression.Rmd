---
title: "SkillCraft Multivariant Regression"
author: "Arrington Walters"
date: "10/7/2020"
output: html_document
bibliography: ./inline/bibliography.bib
---

```{bash git,eval=FALSE  , include=FALSE}
cd ~/STAT757/skillcraft
git add --all
git commit -m "Wrapping up vio explaination. Cleaning up headers. Changing histogram for response"
git push
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r loading_packages,include=FALSE}
library(tidyverse)
library(dbplyr) #piping
library(ggplot2) #plotting
library(gridExtra)# easy plot grids
library(Hmisc) # for correlation matrix
library(corrplot) # For correlation matrix graphic
#library(SC2API) #starcraft 2 API
library(broom) #grabbing p-value
#library(GGally)  ggpairs
```
```{r settoken, include=FALSE}
#set_token("33be678eb46d4f51ac36f72218abcdd2", #"Sb3QWR8A9mN9s0XgAt5w4j0FttY84pkg")
```
```{r midterm2, include=FALSE}
# Assignment Midterm 2

#https://cgrudz.github.io/teaching/stat_757_2020_fall/assets/midterm_2.html
```
# Introduction
 
Videogames are one of my favorite past times. As a player who participates in ranked play, I've always kept my eye on the forefront of global competitions. One of the most notable games to establish a global competitive scene backed by paid professionals was the real-time strategy game (RTS) Starcraft II (SC2). In 2013 the top 10 starcraft players by earnings made nearly four-million dollars from their combined winnings @Winnings2019. Watching top-caliber players reflexes and control is astonishing to even seasoned videogame enthusiasts. At the 2019 StarCraft II World Championship Finale, many others and I packed into the arena to see what these professions could do firsthand.

!['@SC2IIWCSGlobal'](./inline/WCS.png)

The eye watering speeds they perform at is universally referenced in gaming terminology as actions per minute (APMS). Professionals take actions at such fastspeeds (high APMS) it becomes challenging to follow their overall strategy. So past pondering their sheer speed, I found it difficult to distinctly define what made these players professionals.

To learn more about what defines talent in SC2 this analysis we will explore in game metrics in attempts to explain rank in competitive mode. The dataset used was provided by ['@UCI'](https://archive.ics.uci.edu/ml/datasets/SkillCraft1+Master+Table+Dataset).

## Goal

To model the response LeagueIndex a sample of player data from a 2013 ranked season of Starcraft will be explored. The predictors provided summarize in game performance metrics for a season by player (GameID). The modeling process will consider all the predictor variables and then trim down until only significant predictors remain.  Variables will be vetted for multicolinearity and finally The model will be explored for to see if the BLUE assumptions hold.

## Limitations of the Model

The multivariate regression model used for the midterm 2 portions of this study explores the linear estimation of mean response of LeagueIndex estimated by predictors in the design matrix $X$. 

The assumptions of this models explanatory or predict power depends on the residual error of the model being gaussian. Considering LeagueIndex is ordinal variable it is doubtful to be statistically normaly or for the residuals of the model to be as a result.

The levels of LeagueIndex range (1:8) corresponding to player ranks Bronze, Silver, Gold, Platinum, Diamond, Master, Grand Master, and Professional league. Game ranking systems frequently are based on ELO/MMR that varies over a much larger range typically ~1200-3000. These ranges are then masked with medal ranks as listed above and then further subdivided into divisions within each medal @Leagues2019 . Using either MMR or having the subdivisions of each player would provide some much needed continuity but unfortunately neither of these metrics are available. These limitation will be revisited more specifically along the exploration, modeling, and the predictions of the values.

A more suitable form of model for this regression would be based off a Polytonomous Logistic Regression for Ordinal Response (Proportional Odds Model) @OrdinalLog. These methods will be revisited for the final portion of this analysis.

# The Data Exploring

```{r loaddata , include=FALSE}
sc<-read_csv("~/STAT757/skillcraft/SkillCraft1_Dataset.csv")
```

This dataset is a sample of averaged in-game metrics of Starcraft II players who participate in 2013 ranked play. The variables are as follows:
```{r,echo=FALSE}
colnames(sc)
```
The appendix covers each in depth but the following are highlighted because their used in the final analysis.

**LeagueIndex** is was covered thoroughly in the above section. The following are the icon's earned for players who achieve related rank by the end of a given season. The legends for the following plots are styled to match.

\center !['@SC2IIWCSGlobal'](./inline/StarCraft-II-Leagues.png) \center

**Perception Action Cycles (PACs)** are the circular flow of information between an organism and its environment where a sensor-guided sequence of behaviors are iteratively followed towards a goal @Perception. In this dataset PACs are aggregate of screen movements where PAC is a screen fixation of containing at least one action @UCI.

# Cleanliness

```{r ,include=FALSE}
#set type
sc$HoursPerWeek<-as.numeric(sc$HoursPerWeek)
sc$TotalHours<-as.numeric(sc$TotalHours)

count_missing_age<-count(sc%>%
  filter(is.na(Age))%>%arrange(LeagueIndex))
count_professional<-count(sc%>%filter(LeagueIndex==8))
count_grandmaster<-count(sc%>%filter(LeagueIndex==8))
print(paste('There are ',count_missing_age,' missing values in the age column. There are ',count_professional,' professional #players.'))
```

The missing values are related exclusive to players with LeagueIndex equivalent to Professional Players (8). Where the `r count_professional` players with LeagueIndex=8 the age data is NA and the HoursPerWeek are 0. LeagueIndexes 1-7 are obtainable natural game play, to be a professional you would have to be part of a team. I am aiming to understand how players go from being average to good, less so elite to best.The 55 values associated with professionals will be dropped to resolve both issues.

[Question for Colin]: Furthermore while Bronze through Master leagues (**LeagueIndex**'s 1-6) may contain any number of players, Grand Master (**LeagueIndex**=7) may only contain 200 players. To only analyze portions of the data that are "more normal" the `r count_grandmaster` players **LeagueIndex**==7 data will be dropped.

In addition to the missing values we have a clear error with the **TotalHours** of one player. $GameID = 5140$ has 1,000,000 **TotalHours** that equates to 114 years of game time. If we assumed one extra 0 was added the player would still have 14 years of played time on a game that is only 10 years old as of a 2020. Removing two 0s equates to 1.4 years of played time which is much more realistic. Removing 3 zeros results in `r .14*365` days of played time and that seems just as realistic. There is not a clear path to extrapolate this player's true total hours so their data will be dropped from the analysis. This was originally detected during modeling, but brought earlier into that analysis because how obviously unintentional this value is.

```{r,echo=FALSE}
sc<-filter(sc,sc$TotalHours<1000000)
```
Finally, preforming basic a inspection on **HoursPerWeek** a max value of 168 was discovered. Considering there are 168 hours in a week its not plausible for a individual player to do this. There could be multiple players using this account making this possible. Another prospect is that this player is actually an AI like google's DeepMind [https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii]. Either way this observation will be kept because what is realistic cutoff for the hours per week is not apparent and after removing the observation the next max value is 140 which seems almost as unrealistic.

Its worth noting that dropping any amount of high hour outliers far from combats all the issues encountered through the use of **HoursPerWeek** and or **TotalHours**. Multiple players could be using any of the accounts even if the hour are not high. More likely then that many of these accounts could be smurf accounts. Smurfing is when a player makes a additional accounts to have a match making rating reset [https://www.lol-smurfs.com/blog/what-is-a-smurf-account/]. A common reason for doing this is to dominate the competition until their rating adapts to their skill level.

```{r finalclean, include=FALSE ,echo=FALSE}
sc<-sc%>%
  drop_na()%>%
  filter(HoursPerWeek!=0)
sc_describe<-describe(sc)
```

## Converting Units
Some of the time averaged metrics are per SC2 timestamp while other are per milisecond. To make these metrics more interpretable each metric will be converted into seconds. There are roughly 88.5 timestamps per second so each metric in timestamps will be multiplied that as a coefficient  @UCI.

Some of the time averaged metrics are per milisecond. These will be transformed into seconds so the time units are completely uniform.

Both of these transformations are linear and will not affect our model's assumptions.
```{r changeunits, include=FALSE}
sc<-sc%>%
  mutate(NumberOfPACs=NumberOfPACs*88.5,
         MinimapAttacks=MinimapAttacks*88.5,
         MinimapRightClicks=MinimapRightClicks*88.5,
         SelectByHotkeys=SelectByHotkeys*88.5,
         AssignToHotkeys=AssignToHotkeys*88.5,
         UniqueHotkeys=UniqueHotkeys*88.5,
         WorkersMade=WorkersMade*88.5,
         UniqueUnitsMade=UniqueUnitsMade*88.5,
         ComplexUnitsMade=ComplexUnitsMade*88.5,
         ComplexAbilitiesUsed=ComplexAbilitiesUsed*88.5,
         GapBetweenPACs=GapBetweenPACs*1000,
         ActionLatency=ActionLatency*1000)
```


```{r statsatlevels, include=FALSE}
#sc$LeagueIndex <- as.factor(sc$LeagueIndex)
#ggplot(sc, aes(x=LeagueIndex, y=ActionsInPAC)) + 
#  geom_boxplot()
#lm(LeagueIndex~APM,sc)
```

## Summary Statistics and Plots

```{r, echo=FALSE}
#summary(sc)
```

### Correlation Plot

Visually we can see that LeagueIndex has a relatively strong correlation with **APM, SelectByHotkeys, AssignToHotkeys, NumberofPACs, GapBetweenPACs, and Action Latency**. Some of these predictors may be the best choices for model, although its worth noting at this point many of the predictor values also have fairly strong correlations within themselves which may cause multiplecolinearity in a model. This is not too surprising because many of these metrics capture rate of actions in slightly difference forms. For example **APM** and **NumberOfPacs** likely have a strict mathematical relationship where approximately $NumberOfPACs=APM*MatchDurationMinutes$. The slight differences between these metrics them could have some deep explanatory power but that level of explore ration is beyond the scope of this analysis.

The following columns will be dropped because plausible confoundance with **APMs**:
- Remove Action Latency 
- Remove GapBetweenPACs ^[Another issue with this is that its unist do not seem to align with the description. Before and after the unit transformation GapBetweenPACs results in periods that dont make since for the expected duration of SC2 matches.)]
- Remove NumberofPACS
- Remove SelectbyHotkey
- Remove ActionsInPAC

Focusing exclusively on **APM** fits into an Occam's razor approach by minimizing the dimensionality of the models space.

```{r echo=FALSE}
sc_cor<-cor(select_if(sc,is.numeric),use = "complete.obs")
sc_cor_plot<-corrplot(sc_cor,
    tl.cex=.75,
    tl.col='black')
```
```{r droppredictorsandredocor, echo=FALSE}
sc<-sc%>%select(!c(GameID,ActionLatency,GapBetweenPACs,NumberOfPACs,SelectByHotkeys,ActionsInPAC))
```
 
### Visual Inspection

```{r,include=FALSE}
cor_hoursperweek<-paste(
  round(cor(sc%>%filter(between(LeagueIndex,1,4))%>%select(LeagueIndex),
    sc%>%filter(between(LeagueIndex,1,4))%>%select(HoursPerWeek))[1],
    2),
  "vs",
  round(cor(sc%>%filter(between(LeagueIndex,4,7))%>%select(LeagueIndex),
    sc%>%filter(between(LeagueIndex,4,7))%>%select(HoursPerWeek))[1],
    2)
)
```

Visually determining trends between the predictors and the response with a response is that ordinal requires tossing aside scatter plots for a better suited tools. Violinplots will be used to gauge the linearity in relation to the response and distribution with variable at the varying levels https://chartio.com/learn/charts/violin-plot-complete-guide/. 

**MinimapAttacks, HoursPerweek, TotalHours, MinimapRightClicks, ComplexUnitsMade, ComplexAbilitiesUsed** all have very long right tails. In search of gaussian predictors the listed variables are transformed using a square root transformation. The tail of some of predictors remainslong tail thus a log transformation would be preferable, but enough observations by GameID that contain at least 0 in the listed predictor values that the model would have to drop observation containing $-\infty$.

#### No Relationship
**Age** the mean age of `r mean(sc$Age)` does not vary much across **LeaguIndex** such that there is no stark linear relationship. Although the variance at the highest level seems to be much narrower then that at the lower levels. 

#### Bimodal
**HourPerWeek** The square root of **HoursPerWeek** has visibly little or no relation to LeagueIndex 1-4 where LeagueIndex 4-7 seems to have a strong linear trend resulting in `r cor_hoursperweek`. If HoursPerWeek survives the model trimming, it's bimodality may cause issues w model assumption $COV(Y)=\sigma^2I$.**Workersmade,ComplexUnitsMades, and ComplexAbilityUsed** both have similar differences between LeagueIndex 1-4 and 4-7 with the portions that have no relation and a linear relation swapped in comparison to HoursPerWeek. 

#### Linear

**TotalHours, MinimapRightClicks, TotalMapExplored, UniiqueUnitsMade** The square root of HoursPerWeek positive linear trend with the response. **APM** has a strong linear relationship with the response. 

#### Fractional
**AssignToHotkeys, UniqueHotkeys,and MinimapAttacks** The square root of these variablesa notable fractional relationship with the response. This also may cause issues with the Gaussianity of the model's residuals.

```{r colorvector, echo=FALSE}
cbPalette <- c("#CC6600", "#999999", "#FFCC00", "#CCCFFF", "#CCFFFF","#0072B2", "#FF6600")
```

```{r transform, echo=FALSE}
sc[,c("MinimapAttacks", "HoursPerWeek","TotalHours","MinimapRightClicks"
      ,"ComplexUnitsMade","ComplexAbilitiesUsed")]<-sqrt(sc[,c("MinimapAttacks", "HoursPerWeek","TotalHours","MinimapRightClicks"
      ,"ComplexUnitsMade","ComplexAbilitiesUsed")])
```

```{r,echo=FALSE,error=FALSE, compact=TRUE}
VioLeagueIndex<-function(predictor){
  ggplot(sc, aes(x=factor(LeagueIndex), y=unlist(sc%>%select(all_of(predictor))), fill=factor(LeagueIndex))) + 
    geom_violin(trim=FALSE, color="black")+scale_fill_manual(values=cbPalette)+
    stat_summary(fun.data=mean_sdl,geom="pointrange", color="black")+ coord_flip()+
    ggtitle(paste("LeagueIndex by",predictor))+
    xlab("LeagueIndex")+ylab(predictor) + guides(fill= FALSE)
    }

plots<-lapply(colnames(sc)[2:length(colnames(sc))],VioLeagueIndex)

do.call("grid.arrange", c(plots[1:4], ncol=2))
do.call("grid.arrange", c(plots[5:8], ncol=2))
do.call("grid.arrange", c(plots[9:13], ncol=2))
```

### Gaussianity of the Response

When using Shapiro-Wilk W test on response **LeagueIndex** the null hypothesis that the sample  comes from normally distribution can be rejected. Besides the obvious issues with performing a W test with an ordinal response, the the response has a heavy tail with a mean of `r round(mean(sc$LeagueIndex),2)`. Additionally we cannot assume the levels between LeagueIndexes are uniforming spaced. 

[Should I Include:] While the population distribution of ranking is difficult to come by, leagues like Grandmaster (LeagueIndex = 7 ) are capped at 200 which forcibly prevents LeagueIndex 1-7 from having a gaussian distribution.

```{r, echo=FALSE}
LeagueIndex_Normal<-shapiro.test(sc$LeagueIndex)
  ggplot(sc) +
  geom_histogram(aes(x = LeagueIndex, y = (..count..)/sum(..count..),fill=LeagueIndex),
                 position = "identity", binwidth = 1,fill=cbPalette) +
  ylab("Relative Frequency")+
  ggtitle('LeagueIndex Distribution',subtitle = paste(LeagueIndex_Normal[3]," P-Value: ",LeagueIndex_Normal[2]))+
  xlab("LeagueIndex 1-Bronze to 7-Grandmaster")

```

# Model Specifications

```{r exhaustivestepwise,echo=FALSE,collapse=TRUE}

## Stepwise Linear Regression:

#The function summary() reports the best set of variables for each model size. From the output above, an asterisk #specifies that a given variable is included in the corresponding model @Stepwise.


#library(caret) #for easy machine learning workflow
#library(leaps) #for computing stepwise regression

#sc_lm_sw_back<-regsubsets(LeagueIndex~., sc, nvmax = 5,
#                     method = "exhaust",force.in = NULL,force.out = NULL)

#sc_lm_sw_back_summary<-summary(sc_lm_sw_back)
#using the lm provivded 
#sc_lm_r1<-lm(LeagueIndex~ActionLatency+AssignToHotkeys+APM+MinimapAttacks,sc)
#summary(sc_lm_r1,cor=T)

#Normality
#qqnorm(residuals(sc_lm_r1))
#shapiro.test(residuals(sc_lm_r1))
```

## Manual Regression Iterations

I dropped age for as a insignificant predictor, that may mean its not too late for me!
```{r,echo=FALSE}
sc_lm<-lm(LeagueIndex~.,sc)
sc_lm_1<-update(sc_lm,.~.-UniqueUnitsMade ,sc)
sc_lm_2<-update(sc_lm,.~.-Age-UniqueUnitsMade)
sc_lm_3<-update(sc_lm,.~.-Age-UniqueUnitsMade-ComplexUnitsMade)
sc_lm_4<-update(sc_lm,.~.-Age-UniqueUnitsMade-ComplexUnitsMade-MinimapRightClicks)
sc_lm_final<-update(sc_lm,.~.-Age-TotalMapExplored-UniqueUnitsMade-MinimapRightClicks-ComplexUnitsMade)

#anova(sc_lm_1)$'Pr(>F)'
```

*5 Justify your choices using hypothesis testing and confidence intervals for selection of parameters. You should compare multiple model choices in describing this relationship, including the null model. *

*6 Evaluate the goodness of fit of the model in terms of R2 and the standard errors, and the major sources of uncertainty. This includes parameter uncertainty, as well as structural uncertainty in the model. *

Before beginning diagnostic tests, a model with all predictors will be made. Subsequently predictors will be dropped one by one until only predictors with significance of at least$\alpha=5%% remain. The results are as follows:

The null model summary:
```{r, echo=FALSE}
summary(sc_lm)
```
After 4 iterations the all predictors were significant. The final iteration provided:
```{r, echo=FALSE}
summary(sc_lm_final)
```
### Testing for Signifance of Modeling

Our initial $H_o$ is there is no systematic structure to the response LeagueIndex. Our alternative $H_a$ is there is some relation such that $LeagueIndex=X\beta+\epsilon$, where X all other variables with the exception of index GameID. Without much surprise using 18 predictor variables results of a very small p-value of ~`r glance(sc_lm)$p.value `. Over the iteration this does not change in a notable fashion across the 9 other models as the last model also results in a p-value`r glance(sc_lm_4)$p.value`. Thus all iterations of the model we can reject the null hypothesis suggesting that we should further investigate the explanatory power of our alternative hypothesis. 

### Noramlity of Residuals Both Models

```{r}
plot(sc_lm)
plot(sc_lm_final)
```

## Testing for Signifance Between Models

Our second null test is to determine if the the starting and final model's have significantly different residuals. The $H_o$ specifically is that $RSS_{lm1}$ = $RSS_{lm4}$ and $H_a$ is that $RSS_{lm1}$ \neq $RSS_{lmfinal}$. Performing an ANOVA test we find that there is not significant difference in the models at $\alpha=5\%$ such that we cannot reject the $H_o$.(ANOVA see table below). Additionally their $adjR^2$ is barely different. Starting at `r round(summary(sc_lm)[["adj.r.squared"]],2)` and ending at `r round(summary(sc_lm_final)[["adj.r.squared"]],2)`.

```{r,echo=FALSE}
anova(sc_lm,sc_lm_final)
```

```{r}
confint(sc_lm_4)
```

### Exploring the chosen model

Evaluate the goodness of fit of the model in terms of R2
and the standard errors, and the major sources of uncertainty. This includes parameter uncertainty, as well as structural uncertainty in the model. 
```{r, collapse=TRUE}
summary(sc_lm_4,cor='T')
plot(sc_lm_4)
```

```{r alternative model,include=FALSE}
lm_APM<-lm(APM~LeagueIndex*(.),sc)
summary(lm_APM)
qqnorm(residuals(lm_APM))
qqline(residuals(lm_APM))
shapiro.test(residuals(lm_APM))
```

### Model Analysis Reform (Trim and then confound)

Describe your model, how you arrived at it, its goodness of fit, its significance versus other choices of models, and its uncertainty. Describe the predictive power, and the uncertainty. Include relevant tables and figures.

## Predict

Evaluate the predictive power of the model â€“ particularly, how effective does the model appear to be at making predictions of future observations or the mean response. How might these predictions be unreliable? What are the limits of the prediction power, and where do we fall into extrapolation? 

## Prelude to final

*7 Describe your proposed research question for the final. How will you revise your original research question? What issues have you encountered so far? What assumptions do you think you need to (re-)evaluate? *

For the final, the logistical regression will remodel the same problem with a different set of techniques and assumptions that fit the ordinal response.

The goal is for the analysis pull in additional regression techniques while still integrating the previous exploratory exercises.


```{r, eval=FALSE,include=FALSE,include = FALSE}
data <-get_league_data(season_id = 43, 
                        queue_id = 201, 
                        team_type = 0, 
                        league_id = 3, 
                        host_region = "eu")
ladder_id <- data$tier$division[[1]]$ladder_id

for (i in ladder_id){
counter<-0
  if (counter==0){
    headsc <- get_ladder_data(ladder_id = i, host_region = "eu")
    counter<-counter+1}
  else{
    headsc<-rbind(headsc,get_ladder_data(ladder_id = i, host_region = "eu"))
  }
  }
#ladder_data <- get_ladder_data(ladder_id = ladder_id, host_region = "eu")

```

# Appendix

### About Columns
Attribute Information:

1. GameID: Unique ID number for each game (integer)
2. LeagueIndex: Bronze, Silver, Gold, Platinum, Diamond, Master, GrandMaster, and Professional leagues coded 1-8 (Ordinal)
3. Age: Age of each player (integer)
4. HoursPerWeek: Reported hours spent playing per week (integer)
5. TotalHours: Reported total hours spent playing (integer)
6. APM: Action per minute (continuous)
7. SelectByHotkeys: Number of unit or building selections made using hotkeys per timestamp (continuous)
8. AssignToHotkeys: Number of units or buildings assigned to hotkeys per timestamp (continuous)
9. UniqueHotkeys: Number of unique hotkeys used per timestamp (continuous)
10. MinimapAttacks: Number of attack actions on minimap per timestamp (continuous)
11. MinimapRightClicks: number of right-clicks on minimap per timestamp (continuous)
12. NumberOfPACs: Number of PACs per timestamp (continuous)
13. GapBetweenPACs: Mean duration in milliseconds between PACs (continuous)
14. ActionLatency: Mean latency from the onset of a PACs to their first action in milliseconds (continuous)
15. ActionsInPAC: Mean number of actions within each PAC (continuous)
16. TotalMapExplored: The number of 24x24 game coordinate grids viewed by the player per timestamp (continuous)
17. WorkersMade: Number of SCVs, drones, and probes trained per timestamp (continuous)
18. UniqueUnitsMade: Unique unites made per timestamp (continuous)
19. ComplexUnitsMade: Number of ghosts, infestors, and high templars trained per timestamp (continuous)
20. ComplexAbilitiesUsed: Abilities requiring specific targeting instructions used per timestamp (continuous)

# References